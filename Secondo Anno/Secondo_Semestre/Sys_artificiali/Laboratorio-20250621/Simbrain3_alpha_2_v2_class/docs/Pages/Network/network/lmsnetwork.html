<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<title>Simbrain Documentation</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<link href="../../../Styles.css" rel="stylesheet" type="text/css">
</head>

<body>
<a href="../../../SimbrainDocs.html"><div class="logo">
  <p><span></span></p>
</div>
</a>
<div id="main_docs">
  <div class="navi">
    <p><a href="../../../SimbrainDocs.html">Simbrain</a> &gt; <a href="../../Network.html">Network</a> &gt; <a href="../subnetwork.html">Subnetwork</a> &gt; LMS</p>
  </div>
  <p><h1>LMS Network</h1></p>
  <p>The LMS Network is a two layer feed-forward network that implements the standard Least Mean Squares rule for learning. Its neurons and synapses behave like a <a href="standardnetwork.html">standard network</a>, and are updated according to their own neuron rules.  However, a dialog can be called up that trains the synapses according to the Least Mean Squares rule. </p>
  <p>The LMS rule is a form of supervised learning, which means that the user must supply desired output values for each of a list of input values. See <a href="trainingFile.html">training files.</a> </p>
  <p>The LMS rule works as follows. The change in a weight is equal to the product of a learning rate &epsilon;, the pre-synaptic source activation, and the difference between the post-synaptic activation <em>a<sub>j</sub></em> and a desired activation <em>t<sub>j</sub></em>. The error is the difference between the desired and actual activation of the target neuron.</p>
  <p><img src="../equations/LMSRule.png" width="203" height="54"></p>
  <p>Repeated application of this rule mimizes reduces  mean squared error on a set of training data. </p>
  <p>This rule is also known as the &quot;Widrow-Hoff&quot; rule, and the &quot;Delta Rule.&quot; Networks that use these rules are sometimes called &quot;adalines&quot; or &quot;madalines&quot; (for the multilayer case, which these networks do not currently implement). They are descendents of an early form of network studied by Rosenblatt called a &quot;perceptron.&quot;</p>
  <p class="heading">Initialization</p>
  <blockquote>
    <p>Since these are two layer networks, they are initialized with a set number of input and output units. The resulting layer will be two layers of the specified number of neurons with feed-forward connections. </p>
</blockquote>
  <p class="heading">Parameters</p>
  <blockquote>
    <p><span class="heading2">Learning Rate: </span>Learning rate is denoted by &epsilon;. This parameter determines how quickly synapses change. </p>
  </blockquote>
  <p class="heading">Training</p>
  <blockquote>
    <p>To train the LMS network select &quot;Train&quot; in the tab-context menu. (Right click on the <a href="subnetwork_tab.html">subnetwork tab</a> and select &quot;train&quot;). You must set an input and output file. </p>
    <p><span class="heading2">Input File</span>: Use this button to select an input file for training (See <a href="trainingFile.html">training files)</a>. </p>
    <p><span class="heading2">Output File</span>: Use this button to select an output file for training.</p>
    <p><span class="heading2">Randomize Network:</span> Randomize weights  of the  network. </p>
    <p><span class="heading2">User / Play</span>: This repeatedly applies the LMS learning algorithm</p>
    <p><span class="heading2">User / Step</span>: This applies the LMS learning algorithm once to the entire network. </p>
    <p><span class="heading2">Batch / Epochs</span>: In batch mode you specify a specific number of epochs for the algorithm to perform. An epoch is one iteration through the entire dataset. The number of epochs is the number of such complete iterations to perform.</p>
    <p><span class="heading2">Batch / Train</span>: Begin iterating for the number of iterations specified in the epochs field.</p>
    <p><span class="heading2">Props</span>: Set parameters for this network: momentum and learning rate, described above.</p>
    <p><span class="heading2">RMS Error</span>: Displays the current root mean squared error.</p>
  </blockquote>
  <blockquote>&nbsp;</blockquote>
</body>
</html>
